{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service as ChromeService\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.service import Service as ChromeService\n",
    "from selenium.webdriver.chrome.webdriver import WebDriver as ChromeWebDriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import pandas as pd\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import csv\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "import json\n",
    "from selenium.common.exceptions import TimeoutException\n",
    "\n",
    "\n",
    "\n",
    "chrome_service = ChromeService(\"C:\\\\Users\\\\VICTUS\\\\Downloads\\\\chromedriver-win64\\\\chromedriver-win64\\\\chromedriver.exe\")\n",
    "driver = ChromeWebDriver(service=chrome_service)\n",
    "\n",
    "login_url=\"https://shopee.com.my/buyer/login\"\n",
    "driver.get(login_url)\n",
    "\n",
    "\n",
    "language_button = driver.find_element(By.XPATH, '//*[@id=\"modal\"]/div[1]/div[1]/div/div[3]/div[1]/button')\n",
    "language_button.click()\n",
    "\n",
    "username_field = driver.find_element(By.NAME, 'loginKey')\n",
    "password_field = driver.find_element(By.NAME, 'password')\n",
    "\n",
    "# username_field.send_keys(\"amita.ic.19@nitj.ac.in\")\n",
    "# username_field.send_keys(\"amitanand.asqre@gmail.com\")\n",
    "username_field.send_keys(\"sd.amitanand@gmail.com\")\n",
    "password_field.send_keys(\"Amit@1234#\")\n",
    "\n",
    "login_button = driver.find_element(By.XPATH, \"//*[@id='main']/div/div[2]/div/div/div/div[2]/form/div/div[2]/button\")\n",
    "login_button.click()\n",
    "\n",
    "time.sleep(10)\n",
    "\n",
    "\n",
    "product_urls = [\n",
    "    'https://shopee.com.my/New-tide-rimless-sunglasses-ladies-fashion-all-match-UV-protection-sunscreen-sunshade-sunglasses-i.992975877.23941383249?sp_atk=c1860b1e-55b1-445d-86a6-ff85b3d50752&xptdk=c1860b1e-55b1-445d-86a6-ff85b3d50752',\n",
    "    \"https://shopee.com.my/URVOI-Ocean-Band-for-Apple-Watch-Ultra-series-8-7-6-SE-54321-silicone-strap-for-iWatch-sport-stretch-bracelet-49mm-45-44-40-41mm-i.85763660.21448408366?sp_atk=17c56707-9a6d-45fe-aa70-e0cf9393b3a5&xptdk=17c56707-9a6d-45fe-aa70-e0cf9393b3a5\"\n",
    "]\n",
    "\n",
    "csv_filename = \"store.csv\"\n",
    "\n",
    "\n",
    "data = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_customer_name(element):\n",
    "    name=\"\"\n",
    "    try:\n",
    "        name = element.find_element(By.CLASS_NAME, 'shopee-product-rating__author-name').text\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred while extracting name data: {e}\")\n",
    "    return name\n",
    "\n",
    "def extract_profile_url(element):\n",
    "    url=\"\"\n",
    "    try:\n",
    "        url = element.find_element(By.CLASS_NAME, 'shopee-product-rating__author-name').get_attribute(\"href\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred while extracting url data: {e}\")\n",
    "    return url\n",
    "\n",
    "def extract_rating(element):\n",
    "    rating=\"\"\n",
    "    try:\n",
    "        svg_elements = element.find_element(By.CLASS_NAME, 'shopee-product-rating__rating')\n",
    "        rating = len(svg_elements.find_elements(By.CLASS_NAME, 'icon-rating-solid--active'))\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred while extracting rating data: {e}\")\n",
    "    return rating\n",
    "\n",
    "def extract_time(element):\n",
    "    time=\"\"\n",
    "    try:\n",
    "        time = element.find_element(By.CLASS_NAME, 'shopee-product-rating__time').text\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred while extracting time data: {e}\")\n",
    "    return time\n",
    "\n",
    "def extract_review_data(element):\n",
    "    review_data = \"\"\n",
    "    try:\n",
    "        container = element.find_element(By.CSS_SELECTOR, '.Rk6V\\\\+3')\n",
    "        div_elements = container.find_elements(By.TAG_NAME, \"div\")\n",
    "        for div in div_elements:\n",
    "            text = div.text.strip()\n",
    "            if text: \n",
    "                review_data += text + '\\n'\n",
    "    except NoSuchElementException as e:\n",
    "        return review_data \n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred while extracting review data: {e}\")\n",
    "    return review_data\n",
    "\n",
    "def extract_image_url(element):\n",
    "    image_urls = []\n",
    "    try:\n",
    "        parent_element = element.find_element(By.CLASS_NAME, \"rating-media-list__zoomed-image\")\n",
    "        image_elements = parent_element.find_elements(By.TAG_NAME, \"img\")\n",
    "        urls = [element.get_attribute(\"src\") for element in image_elements]\n",
    "        image_urls = urls\n",
    "    except NoSuchElementException as e:\n",
    "        return image_urls \n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred while extracting image URLs: {e}\")\n",
    "    return image_urls\n",
    "\n",
    "def extract_video_url(element):\n",
    "    video_urls = []\n",
    "    try:\n",
    "        parent_element = element.find_element(By.CLASS_NAME, \"rating-media-list__zoomed-image\")\n",
    "        video_elements = parent_element.find_elements(By.TAG_NAME, \"video\")\n",
    "        urls = [element.get_attribute(\"src\") for element in video_elements]\n",
    "        video_urls = urls\n",
    "    except NoSuchElementException as e:\n",
    "        return video_urls \n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred while extracting image URLs: {e}\")\n",
    "    return video_urls\n",
    "\n",
    "def extract_likes(element):\n",
    "    likes=\"\"\n",
    "    try:\n",
    "        likes = element.find_element(By.CLASS_NAME, 'shopee-product-rating__like-count').text\n",
    "        if likes == \"Helpful?\":\n",
    "            likes = 0\n",
    "    except NoSuchElementException as e:\n",
    "        return 0 \n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred while extracting image URLs: {e}\")\n",
    "    return likes\n",
    "\n",
    "def scrape_historical_reviews(url):\n",
    "    reviews = []\n",
    "\n",
    "    try:\n",
    "        driver.get(url)\n",
    "\n",
    "        scroll_count = 5\n",
    "        for _ in range(scroll_count):\n",
    "            driver.find_element(By.TAG_NAME, 'body').send_keys(Keys.END)\n",
    "            time.sleep(2)\n",
    "\n",
    "        product_name = driver.find_element(By.CLASS_NAME, \"_44qnta\").text\n",
    "\n",
    "        current_page = 1  \n",
    "        while True:\n",
    "            parent_elements=driver.find_elements(By.CLASS_NAME, \"shopee-product-rating__main\")\n",
    "            \n",
    "            if parent_elements:\n",
    "                for i in range(len(parent_elements)):\n",
    "                    customer_name = extract_customer_name(parent_elements[i])\n",
    "                    customer_profile_url = extract_profile_url(parent_elements[i])\n",
    "                    rating = extract_rating(parent_elements[i])\n",
    "                    timeStamp=extract_time(parent_elements[i])\n",
    "                    review = extract_review_data(parent_elements[i])\n",
    "                    video_urls=extract_video_url(parent_elements[i])\n",
    "                    image_urls=extract_image_url(parent_elements[i])\n",
    "                    media_urls=video_urls+image_urls\n",
    "                    likes = extract_likes(parent_elements[i])\n",
    "                    reviews.append([product_name, url, \"Historical\", customer_name, customer_profile_url, rating, timeStamp, review, media_urls, likes])\n",
    "\n",
    "            try:\n",
    "                next_page_button = WebDriverWait(driver, 10).until(\n",
    "                    EC.element_to_be_clickable((By.CLASS_NAME, 'shopee-icon-button--right'))\n",
    "                )\n",
    "                ActionChains(driver).move_to_element(next_page_button).perform()\n",
    "                next_page_button.click()\n",
    "                time.sleep(2)\n",
    "                new_page = driver.find_element(By.CLASS_NAME, 'shopee-button-solid.shopee-button-solid--primary').text\n",
    "                if new_page == str(current_page):\n",
    "                    break\n",
    "                current_page = new_page\n",
    "            except TimeoutException:\n",
    "                print(\"Pagination button is not clickable. Exiting pagination.\")\n",
    "                break\n",
    "            except Exception as e:\n",
    "                print(f\"An error occurred while navigating to the next page: {e}\")\n",
    "                break\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "\n",
    "    return reviews\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping completed. Data saved in 'store.json'.\n"
     ]
    }
   ],
   "source": [
    "# To Store in Json format\n",
    "\n",
    "for url in product_urls:\n",
    "    historical_reviews = scrape_historical_reviews(url)\n",
    "\n",
    "    for review in historical_reviews:\n",
    "        data.append({\n",
    "            \"Radarly pid\": 6127,\n",
    "            \"Radarly corpusId\": 64143,\n",
    "            \"Radarly corpusName\": \"Feminine Care\",\n",
    "            \"Product_Name\": review[0],\n",
    "            \"Product_url\": review[1],\n",
    "            \"Status\": review[2],\n",
    "            \"Name\": review[3],\n",
    "            \"Customer_Profile_Url\": review[4],\n",
    "            \"Rating\": review[5],\n",
    "            \"TimeStamps\": review[6],\n",
    "            \"Review\": review[7],\n",
    "            \"Media_Url\": review[8],\n",
    "            \"Likes\": review[9],\n",
    "            \"Id\": \"\"\n",
    "        })\n",
    "\n",
    "json_filename = \"store.json\"\n",
    "with open(json_filename, 'w', encoding='utf-8') as json_file:\n",
    "    json.dump(data, json_file, ensure_ascii=False, indent=4)\n",
    "\n",
    "print(f\"Scraping completed. Data saved in '{json_filename}'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To store in csv file\n",
    "\n",
    "with open(csv_filename, mode='w', newline='', encoding='utf-8') as csv_file:\n",
    "    csv_writer = csv.writer(csv_file)\n",
    "    csv_writer.writerow([\"Radarly pid\", \"Radarly corpusId\", \"Radarly corpusName\", \"Product_Name\", \"Product_url\",  \"Status\", \"Name\", \"Customer_Profile_Url\", \"Rating\", \"TimeStamps\", \"Review\", \"Media_Url\", \"Likes\", \"Id\"])\n",
    "    \n",
    "    for url in product_urls:\n",
    "        historical_reviews = scrape_historical_reviews(url)\n",
    "\n",
    "        for review in historical_reviews:\n",
    "            csv_writer.writerow([6127, 64143, \"Feminine Care\", review[0], review[1], review[2], review[3], review[4], review[5], review[6], review[7], review[8], review[9], \"\"])\n",
    "\n",
    "print(f\"Scraping completed. Data saved in '{csv_filename}'.\")\n",
    "\n",
    "df=pd.read_csv(\"store.csv\")\n",
    "df\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
